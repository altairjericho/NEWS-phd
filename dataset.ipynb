{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import os, re, gc, h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "copa = np.array([np.zeros((3,3)),np.ones((3,3))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copa[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, name_dir='C30keV', n_pols=8):\n",
    "    \"\"\"\n",
    "    Loads images into numpy array of shape (N,h,w,n_pols)\n",
    "    \n",
    "    Arguments:\n",
    "    path -- path to the directory with images\n",
    "    name_dir -- name of the particular directory with signal or bckg samples\n",
    "    n_pols -- number of polarizations (channels) of each image\n",
    "    \n",
    "    Returns:\n",
    "    images -- numpy array with N images of shape (h,w) with n_pols channels\n",
    "    \"\"\"\n",
    "\n",
    "    img_ind = []\n",
    "    path = path+name_dir+\"/csvs/\"\n",
    "    img_names = os.listdir(path)\n",
    "    for name in img_names:\n",
    "        img_ind.append(list(filter(None, re.split('[_.^a-z]',name))))\n",
    "    img_ind = pd.DataFrame(np.array(img_ind), columns=['HeaderID','GrainID','ClusterID','Pol'])\n",
    "    img_ind = img_ind.sort_values(by=['HeaderID','GrainID','Pol'])\n",
    "    for hd in np.unique(img_ind['HeaderID']):\n",
    "        hd_imgs = img_ind[ img_ind['HeaderID']==hd ]\n",
    "        for grain in np.unique(hd_imgs['GrainID']):\n",
    "            grain_imgs = hd_imgs[ hd_imgs['GrainID']==grain ]\n",
    "            if grain_imgs.shape[0]!=n_pols:\n",
    "                img_ind = img_ind.drop(grain_imgs.index)\n",
    "    img_names = []\n",
    "    for name in img_ind.values:\n",
    "        img_names.append(name[0]+'_gr'+name[1]+'_cl'+name[2]+'_pol'+name[3]+'.csv')\n",
    "    \n",
    "    gc.collect()\n",
    "    i=0\n",
    "    im_array = []\n",
    "    for name in img_names:\n",
    "        if i==0:\n",
    "            tmp_im = []\n",
    "            tmp_im.append(pd.read_csv(path+name, header=None).drop(32, axis=1).values)\n",
    "        else: tmp_im.append(pd.read_csv(path+name, header=None).drop([0,33], axis=1).drop(32,axis=0).values)\n",
    "        i+=1\n",
    "        if i==n_pols:\n",
    "            im_array.append(np.array(tmp_im, dtype=np.uint8).T)\n",
    "            i=0\n",
    "            gc.collect()\n",
    "    return np.array(im_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pol_feat(id_frame, n_pol, path_dir, class_name, feat_names):\n",
    "    \n",
    "    f = ROOT.TFile.Open(path_dir+class_name+'/dm_tracks.dm.root','read')\n",
    "    t = f.Get('Vdmr')\n",
    "    all_feat = np.zeros((0,len(feat_names)*n_pol))\n",
    "    feat_array = []\n",
    "    for i in range(n_pol):\n",
    "        for name in feat_names:\n",
    "            feat_array.append(name+str(i))\n",
    "    \n",
    "    eps=1e-3\n",
    "    for hdr, *cl_ids in id_frame.drop(['ViewID','GrainID','tr_flag'], axis=1).values:\n",
    "        pol_feat = []\n",
    "        t.GetEntry(int(hdr))\n",
    "        for cl_id in cl_ids:\n",
    "            for name in feat_names[:-1]:\n",
    "                pol_feat.append(t.GetLeaf('cl.'+name).GetValue(int(cl_id)))\n",
    "            pol_feat.append( (t.GetLeaf('cl.lx').GetValue(int(cl_id))+eps)/(t.GetLeaf('cl.ly').GetValue(int(cl_id))+eps) )\n",
    "        all_feat = np.vstack((all_feat, pol_feat))\n",
    "        gc.collect()\n",
    "    return pd.DataFrame(all_feat, columns=feat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_zero_images(data, bad = None, class_name='C100keV'):\n",
    "    \"\"\"\n",
    "    Removes images (or any entries) mentioned as 'bad', or containing zero pixels (if 'bad' is not specified)\n",
    "    \n",
    "    Arguments:\n",
    "    data -- NumPy array with data to be cleaned\n",
    "    bad -- list of indices to be removed. If None - images containing zero pixels are removed\n",
    "    class_name -- str, name of the data used for saving the 'bad' list, if 'bad' is not specified\n",
    "    \n",
    "    Returns:\n",
    "    data -- NumPy array with 'bad' items removed\n",
    "    \"\"\"\n",
    "    if bad is None:\n",
    "        bad = []\n",
    "        for i in np.arange(data.shape[0]):\n",
    "            if not data[i].all():\n",
    "                bad.append(i)\n",
    "        np.savetxt('bad_edge_'+class_name+'.txt',bad,fmt='%d')\n",
    "        print(class_name+' bad samples: ',len(bad))\n",
    "    mask = np.ones(data.shape[0],dtype=bool)\n",
    "    \n",
    "    mask[bad] = False\n",
    "    return data[mask,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/scanner-ml/Artem/\"\n",
    "class_names = ['C30keV','C60keV','gamma']\n",
    "n_pols = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '/home/scanner-ml/Artem/'\n",
    "class_names_ft = ['C30keV','C60keV','C100keV/C1','C100keV/C2','gamma']\n",
    "class_keys = ['C30keV','C60keV','C100keV','gamma']\n",
    "feat_names = ['x','y','z','lx','ly','phi','npx','vol','eps']\n",
    "id_header = ['HeaderID','ViewID','GrainID','pol0','pol1','pol2','pol3','pol4','pol5','pol6','pol7','tr_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasamples'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "C30 = load_images(path, 'C30keV')\n",
    "C30 = clean_zero_images(C30, class_name='C30keV')\n",
    "gc.collect()\n",
    "C60 = load_images(path, 'C60keV')\n",
    "C60 = clean_zero_images(C60, class_name='C60keV')\n",
    "gc.collect()\n",
    "C100 = load_images(path, 'C100keV/C1')\n",
    "C100 = clean_zero_images(C100, class_name='C100keV')\n",
    "gc.collect()\n",
    "C100_2 = load_images(path, 'C100keV/C2')\n",
    "C100_2 = clean_zero_images(C100_2, class_name='C100keV')\n",
    "gc.collect()\n",
    "gamma = load_images(path, 'gamma')\n",
    "gamma = clean_zero_images(gamma, class_name='gamma')\n",
    "gc.collect()\n",
    "\n",
    "#if os.path.isfile('samples.h5'):\n",
    "#    os.remove('samples.h5')\n",
    "\n",
    "with h5py.File('samples.h5','a') as datafile:\n",
    "    datafile.create_dataset('C30keV', data=C30)\n",
    "    datafile.create_dataset('C60keV', data=C60)\n",
    "    datafile.create_dataset('C100keV', data=np.vstack((C100,C100_2)))\n",
    "    datafile.create_dataset('gamma', data=gamma)\n",
    "    \n",
    "print('gamma samples: ',gamma.shape, '\\t', getsizeof(gamma)//1024**2, 'Mb')\n",
    "print('C100keV_1 samples: ',C100.shape, '\\t', getsizeof(C100)//1024**2, 'Mb')\n",
    "print('C100keV_2 samples: ',C100_2.shape, '\\t', getsizeof(C100_2)//1024**2, 'Mb')\n",
    "print('C60keV samples: ',C60.shape, '\\t', getsizeof(C60)//1024**2, 'Mb')\n",
    "print('C30keV samples: ',C30.shape, '\\t', getsizeof(C30)//1024**2, 'Mb')\n",
    "'''\n",
    "'datasamples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'load_features. wall time ~4h. cpu time ~24h'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "pol_ids = {}\n",
    "for name in class_names:\n",
    "    pol_ids[name] = pd.read_csv(path_dir+name+'/yandex_bfcl.txt', header=None, names=id_header)\n",
    "    pol_ids[name] = pol_ids[name].sort_values(by=['HeaderID','GrainID'])\n",
    "feat_data = {}\n",
    "for name in class_names_ft:\n",
    "    feat_data[name] = get_pol_feat(pol_ids[name], n_pol=8, path_dir=path_dir, class_name=name, feat_names=feat_names)\n",
    "'''\n",
    "'load_features. wall time ~4h. cpu time ~24h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cleaning samples with \"zero-images\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "bads = {}\n",
    "for k in class_keys:\n",
    "    bads[k] = np.loadtxt('/home/scanner-ml/Artem/Python/NEWS/data/bad_edge_'+k+'.txt', dtype=np.int)\n",
    "for k in class_keys:\n",
    "    if k=='C100keV':\n",
    "        feat_data['C100keV/C2'] = clean_zero_images(feat_data['C100keV/C2'].values, bads[k])\n",
    "    else:\n",
    "        feat_data[k] = clean_zero_images(feat_data[k].values, bads[k], class_name=k)\n",
    "\n",
    "### for C100keV/C1 we removed random images, since we didn't save the right indices. Must be fixed!\n",
    "\n",
    "rand_bad = np.ones(feat_data['C100keV/C1'].shape[0], dtype=bool)\n",
    "rand_bad[np.random.randint(0, high=feat_data['C100keV/C1'].shape[0], size=32, dtype=np.int)] = False\n",
    "feat_data['C100keV/C1'] = (feat_data['C100keV/C1'].values)[rand_bad,...]\n",
    "'''\n",
    "'cleaning samples with \"zero-images\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = '''\n",
    "with h5py.File('/home/scanner-ml/Artem/Python/NEWS/data/features.h5','a') as datafile:\n",
    "    datafile.create_dataset('C30keV', data=feat_data['C30keV'])\n",
    "    datafile.create_dataset('C60keV', data=feat_data['C60keV'])\n",
    "    datafile.create_dataset('C100keV', data=np.vstack((feat_data['C100keV/C1'],feat_data['C100keV/C2'])))\n",
    "    datafile.create_dataset('gamma', data=feat_data['gamma'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C100keV', 'C30keV', 'C60keV', 'gamma']\n",
      "['C100keV', 'C30keV', 'C60keV', 'gamma']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('samples.h5','r') as sampfile:\n",
    "    with h5py.File('features.h5','r') as featfile:\n",
    "        print(list(sampfile.keys()))\n",
    "        print(list(featfile.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_test_split'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "if os.path.isfile('dataset.h5'):\n",
    "    os.remove('dataset.h5')\n",
    "with h5py.File('dataset.h5','a') as datafile:\n",
    "    with h5py.File('samples.h5','r') as sampfile:\n",
    "        with h5py.File('features.h5','r') as featfile:\n",
    "            for k in sampfile.keys():\n",
    "                datas = sampfile[k][...]\n",
    "                feats = featfile[k][...]\n",
    "                im_train, im_test, ft_train, ft_test = train_test_split(datas, feats, test_size=0.15)\n",
    "                datafile.create_dataset(k+'/images/train', data=im_train)\n",
    "                datafile.create_dataset(k+'/images/test', data=im_test)\n",
    "                datafile.create_dataset(k+'/features/train', data=ft_train)\n",
    "                datafile.create_dataset(k+'/features/test', data=ft_test)\n",
    "                gc.collect()\n",
    "    print(list(datafile.keys()))\n",
    "'''\n",
    "'train_test_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C100keV/features/test\t (22425, 72)\n",
      "C100keV/features/train\t (127075, 72)\n",
      "C100keV/images/test\t (22425, 32, 32, 8)\n",
      "C100keV/images/train\t (127075, 32, 32, 8)\n",
      "C30keV/features/test\t (17493, 72)\n",
      "C30keV/features/train\t (99125, 72)\n",
      "C30keV/images/test\t (17493, 32, 32, 8)\n",
      "C30keV/images/train\t (99125, 32, 32, 8)\n",
      "C60keV/features/test\t (18670, 72)\n",
      "C60keV/features/train\t (105795, 72)\n",
      "C60keV/images/test\t (18670, 32, 32, 8)\n",
      "C60keV/images/train\t (105795, 32, 32, 8)\n",
      "gamma/features/test\t (19329, 72)\n",
      "gamma/features/train\t (109528, 72)\n",
      "gamma/images/test\t (19329, 32, 32, 8)\n",
      "gamma/images/train\t (109528, 32, 32, 8)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('dataset.h5','r') as datafile:\n",
    "    for k in datafile.keys():\n",
    "        for p in datafile[k].keys():\n",
    "            for n in datafile[k+'/'+p].keys():\n",
    "                print(k+'/'+p+'/'+n+'\\t', datafile[k+'/'+p+'/'+n].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example of loading the libDMRoot in PyROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TClass::Init>: no dictionary for class DMRViewHeader is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRAffine2D is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRCluster is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRGrain is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRMicrotrack is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRImageCl is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRImage is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRFrame is available\n"
     ]
    }
   ],
   "source": [
    "f = ROOT.TFile.Open(path_dir+'C60keV/dm_tracks.dm.root','read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TCling::RegisterModule>: cannot find dictionary module DMRootCint_rdict.pcm\n"
     ]
    }
   ],
   "source": [
    "ROOT.gSystem.Load('libDMRoot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMRRun::OpenNew : Open new file dm_tracks.dm.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRCluster with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRGrain with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRMicrotrack with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRImageCl with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRFrame with a custom Streamer\n"
     ]
    }
   ],
   "source": [
    "arun = ROOT.DMRRun(\"dm_tracks.dm.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
