{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '/home/scanner-ml/Artem/'\n",
    "class_names = ['C30keV','C60keV','C100keV/C1','C100keV/C2','gamma']\n",
    "class_keys = ['C30keV','C60keV','C100keV','gamma']\n",
    "feat_names = ['x','y','z','lx','ly','phi','npx','vol','eps']\n",
    "id_header = ['HeaderID','ViewID','GrainID','pol0','pol1','pol2','pol3','pol4','pol5','pol6','pol7','tr_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example of loading the libDMRoot in PyROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TClass::Init>: no dictionary for class DMRViewHeader is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRAffine2D is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRCluster is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRGrain is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRMicrotrack is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRImageCl is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRImage is available\n",
      "Warning in <TClass::Init>: no dictionary for class DMRFrame is available\n"
     ]
    }
   ],
   "source": [
    "f = ROOT.TFile.Open(path_dir+'C60keV/dm_tracks.dm.root','read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TCling::RegisterModule>: cannot find dictionary module DMRootCint_rdict.pcm\n"
     ]
    }
   ],
   "source": [
    "ROOT.gSystem.Load('libDMRoot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMRRun::OpenNew : Open new file dm_tracks.dm.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRCluster with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRGrain with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRMicrotrack with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRImageCl with a custom Streamer\n",
      "Warning in <TTree::Bronch>: Using split mode on a class: DMRFrame with a custom Streamer\n"
     ]
    }
   ],
   "source": [
    "arun = ROOT.DMRRun(\"dm_tracks.dm.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pol_feat(id_frame, n_pol, path_dir, class_name, feat_names):\n",
    "    \n",
    "    f = ROOT.TFile.Open(path_dir+class_name+'/dm_tracks.dm.root','read')\n",
    "    t = f.Get('Vdmr')\n",
    "    all_feat = np.zeros((0,len(feat_names)*n_pol))\n",
    "    feat_array = []\n",
    "    for i in range(n_pol):\n",
    "        for name in feat_names:\n",
    "            feat_array.append(name+str(i))\n",
    "    \n",
    "    eps=1e-3\n",
    "    for hdr, *cl_ids in id_frame.drop(['ViewID','GrainID','tr_flag'], axis=1).values:\n",
    "        pol_feat = []\n",
    "        t.GetEntry(int(hdr))\n",
    "        for cl_id in cl_ids:\n",
    "            for name in feat_names[:-1]:\n",
    "                pol_feat.append(t.GetLeaf('cl.'+name).GetValue(int(cl_id)))\n",
    "            pol_feat.append( (t.GetLeaf('cl.lx').GetValue(int(cl_id))+eps)/(t.GetLeaf('cl.ly').GetValue(int(cl_id))+eps) )\n",
    "        all_feat = np.vstack((all_feat, pol_feat))\n",
    "        gc.collect()\n",
    "    return pd.DataFrame(all_feat, columns=feat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 505 ms, sys: 72 ms, total: 577 ms\n",
      "Wall time: 574 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pol_ids = {}\n",
    "for name in class_names:\n",
    "    pol_ids[name] = pd.read_csv(path_dir+name+'/yandex_bfcl.txt', header=None, names=id_header)\n",
    "    pol_ids[name] = pol_ids[name].sort_values(by=['HeaderID','GrainID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22h 24min 8s, sys: 1h 39min 6s, total: 1d 3min 15s\n",
      "Wall time: 4h 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feat_data = {}\n",
    "for name in class_names:\n",
    "    feat_data[name] = get_pol_feat(pol_ids[name], n_pol=8, path_dir=path_dir, class_name=name, feat_names=feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127051, 72)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data['C60keV'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_zero_images(data, bad = None, class_name='C100keV'):\n",
    "    \"\"\"\n",
    "    Removes images (or any entries) mentioned as 'bad', or containing zero pixels (if 'bad' is not specified)\n",
    "    \n",
    "    Arguments:\n",
    "    data -- NumPy array with data to be cleaned\n",
    "    bad -- list of indices to be removed. If None - images containing zero pixels are removed\n",
    "    class_name -- str, name of the data used for saving the 'bad' list, if 'bad' is not specified\n",
    "    \n",
    "    Returns:\n",
    "    data -- NumPy array with 'bad' items removed\n",
    "    \"\"\"\n",
    "    if bad is None:\n",
    "        bad = []\n",
    "        for i in np.arange(data.shape[0]):\n",
    "            if not data[i].all():\n",
    "                bad.append(i)\n",
    "        np.savetxt('bad_edge_'+class_name+'.txt',bad,fmt='%d')\n",
    "        print(class_name+' bad samples: ',len(bad))\n",
    "    mask = np.ones(data.shape[0],dtype=bool)\n",
    "    \n",
    "    mask[bad] = False\n",
    "    return data[mask,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = {}\n",
    "for k in class_keys:\n",
    "    bads[k] = np.loadtxt('/home/scanner-ml/Artem/Python/NEWS/data/bad_edge_'+k+'.txt', dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in class_keys:\n",
    "    if k=='C100keV':\n",
    "        feat_data['C100keV/C2'] = clean_zero_images(feat_data['C100keV/C2'].values, bads[k])\n",
    "    else:\n",
    "        feat_data[k] = clean_zero_images(feat_data[k].values, bads[k], class_name=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for C100keV/C1 we removed random images, since we didn't save the right indices. Must be fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_bad = np.ones(feat_data['C100keV/C1'].shape[0], dtype=bool)\n",
    "rand_bad[np.random.randint(0, high=feat_data['C100keV/C1'].shape[0], size=32, dtype=np.int)] = False\n",
    "feat_data['C100keV/C1'] = (feat_data['C100keV/C1'].values)[rand_bad,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('/home/scanner-ml/Artem/Python/NEWS/data/features.h5','a') as datafile:\n",
    "    datafile.create_dataset('C30keV', data=feat_data['C30keV'])\n",
    "    datafile.create_dataset('C60keV', data=feat_data['C60keV'])\n",
    "    datafile.create_dataset('C100keV', data=np.vstack((feat_data['C100keV/C1'],feat_data['C100keV/C2'])))\n",
    "    datafile.create_dataset('gamma', data=feat_data['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C100keV\t (149500, 72)\n",
      "C30keV\t (116618, 72)\n",
      "C60keV\t (124465, 72)\n",
      "gamma\t (128857, 72)\n",
      "\n",
      "\n",
      "C100keV\t (149500, 32, 32, 8)\n",
      "C30keV\t (116618, 32, 32, 8)\n",
      "C60keV\t (124465, 32, 32, 8)\n",
      "gamma\t (128857, 32, 32, 8)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/home/scanner-ml/Artem/Python/NEWS/data/features.h5','r') as datafile:\n",
    "    for k in datafile.keys():\n",
    "        print(k+'\\t',datafile[k].shape)\n",
    "print('\\n')\n",
    "with h5py.File('/home/scanner-ml/Artem/Python/NEWS/data/samples.h5','r') as datafile:\n",
    "    for k in datafile.keys():\n",
    "        print(k+'\\t',datafile[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
